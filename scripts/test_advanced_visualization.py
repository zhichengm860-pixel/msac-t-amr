#!/usr/bin/env python3
"""
é«˜çº§å¯è§†åŒ–å·¥å…·æµ‹è¯•æ–‡ä»¶

ä½œè€…: Assistant
æ—¥æœŸ: 2025-01-16
"""

import os
import sys
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from advanced_visualization import AdvancedVisualizer, FeatureExtractor, AttentionVisualizer

def test_feature_extractor():
    """æµ‹è¯•ç‰¹å¾æå–å™¨"""
    print("=" * 50)
    print("æµ‹è¯•ç‰¹å¾æå–å™¨")
    print("=" * 50)
    
    # åˆ›å»ºç®€å•æ¨¡å‹
    class SimpleModel(nn.Module):
        def __init__(self):
            super().__init__()
            self.conv1 = nn.Conv1d(2, 16, 7)
            self.conv2 = nn.Conv1d(16, 32, 5)
            self.fc = nn.Linear(32, 11)
            
        def forward(self, x):
            x = F.relu(self.conv1(x))
            x = F.relu(self.conv2(x))
            x = F.adaptive_avg_pool1d(x, 1).squeeze(-1)
            return self.fc(x)
    
    model = SimpleModel()
    extractor = FeatureExtractor(model)
    
    # æ³¨å†Œé’©å­
    layer_names = extractor.register_hooks()
    print(f"æ³¨å†Œçš„å±‚: {layer_names}")
    
    # æµ‹è¯•ç‰¹å¾æå–
    test_data = torch.randn(5, 2, 100)
    features = extractor.extract_features(test_data)
    
    print(f"æå–çš„ç‰¹å¾å±‚æ•°: {len(features)}")
    for name, feature in features.items():
        print(f"  {name}: {feature.shape}")
    
    # æ¸…ç†
    extractor.remove_hooks()
    print("ç‰¹å¾æå–å™¨æµ‹è¯•å®Œæˆ!")
    return True

def test_attention_visualizer():
    """æµ‹è¯•æ³¨æ„åŠ›å¯è§†åŒ–å™¨"""
    print("=" * 50)
    print("æµ‹è¯•æ³¨æ„åŠ›å¯è§†åŒ–å™¨")
    print("=" * 50)
    
    # åˆ›å»ºå¸¦æ³¨æ„åŠ›çš„æ¨¡å‹
    class AttentionModel(nn.Module):
        def __init__(self):
            super().__init__()
            self.conv = nn.Conv1d(2, 32, 7)
            self.attention = nn.MultiheadAttention(32, 4, batch_first=True)
            self.fc = nn.Linear(32, 11)
            
        def forward(self, x):
            x = F.relu(self.conv(x))  # [B, 32, L]
            x = x.transpose(1, 2)     # [B, L, 32]
            
            # æ³¨æ„åŠ›æœºåˆ¶
            attn_output, attn_weights = self.attention(x, x, x)
            self.attention_weights = attn_weights  # ä¿å­˜æ³¨æ„åŠ›æƒé‡
            
            x = attn_output.mean(dim=1)  # å…¨å±€å¹³å‡æ± åŒ–
            return self.fc(x)
    
    model = AttentionModel()
    visualizer = AttentionVisualizer(model)
    
    # æµ‹è¯•æ³¨æ„åŠ›æƒé‡æå–
    test_data = torch.randn(3, 2, 50)
    attention_weights = visualizer.extract_attention_weights(test_data)
    
    print(f"æå–çš„æ³¨æ„åŠ›æƒé‡: {len(attention_weights)}")
    for name, weights in attention_weights.items():
        print(f"  {name}: {weights.shape}")
    
    # æµ‹è¯•æ³¨æ„åŠ›çƒ­å›¾
    if attention_weights:
        for name, weights in attention_weights.items():
            fig = visualizer.visualize_attention_heatmap(weights, sample_idx=0)
            print(f"  ç”Ÿæˆæ³¨æ„åŠ›çƒ­å›¾: {name}")
            break
    
    print("æ³¨æ„åŠ›å¯è§†åŒ–å™¨æµ‹è¯•å®Œæˆ!")
    return True

def test_advanced_visualizer():
    """æµ‹è¯•é«˜çº§å¯è§†åŒ–å™¨"""
    print("=" * 50)
    print("æµ‹è¯•é«˜çº§å¯è§†åŒ–å™¨")
    print("=" * 50)
    
    # åˆ›å»ºæµ‹è¯•æ¨¡å‹
    class TestModel(nn.Module):
        def __init__(self, input_channels=2, num_classes=11):
            super().__init__()
            self.conv1 = nn.Conv1d(input_channels, 32, 7, padding=3)
            self.conv2 = nn.Conv1d(32, 64, 5, padding=2)
            self.conv3 = nn.Conv1d(64, 128, 3, padding=1)
            self.pool = nn.AdaptiveAvgPool1d(1)
            self.fc1 = nn.Linear(128, 64)
            self.fc2 = nn.Linear(64, num_classes)
            self.dropout = nn.Dropout(0.2)
            
        def forward(self, x):
            x = F.relu(self.conv1(x))
            x = F.relu(self.conv2(x))
            x = F.relu(self.conv3(x))
            x = self.pool(x).squeeze(-1)
            x = F.relu(self.fc1(x))
            x = self.dropout(x)
            return self.fc2(x)
    
    model = TestModel()
    visualizer = AdvancedVisualizer(model)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    num_samples = 50
    test_data = torch.randn(num_samples, 2, 1024)
    test_labels = torch.randint(0, 11, (num_samples,))
    
    print(f"æµ‹è¯•æ•°æ®å½¢çŠ¶: {test_data.shape}")
    print(f"æµ‹è¯•æ ‡ç­¾å½¢çŠ¶: {test_labels.shape}")
    
    # 1. æµ‹è¯•æ··æ·†çŸ©é˜µ
    print("\\n1. æµ‹è¯•æ··æ·†çŸ©é˜µ...")
    with torch.no_grad():
        outputs = model(test_data)
        predictions = torch.argmax(outputs, dim=1)
    
    cm_fig = visualizer.create_confusion_matrix(
        test_labels.numpy(), predictions.numpy()
    )
    print("   æ··æ·†çŸ©é˜µåˆ›å»ºæˆåŠŸ!")
    
    # 2. æµ‹è¯•ç‰¹å¾æå–å’Œt-SNE
    print("\\n2. æµ‹è¯•t-SNEå¯è§†åŒ–...")
    layer_names = visualizer.feature_extractor.register_hooks()
    features = visualizer.feature_extractor.extract_features(test_data)
    
    if features:
        last_layer = list(features.keys())[-1]
        last_features = features[last_layer]
        
        tsne_fig = visualizer.create_tsne_visualization(last_features, test_labels)
        print("   t-SNEå¯è§†åŒ–åˆ›å»ºæˆåŠŸ!")
        
        # 3. æµ‹è¯•äº¤äº’å¼å¯è§†åŒ–
        print("\\n3. æµ‹è¯•äº¤äº’å¼3Då¯è§†åŒ–...")
        interactive_fig = visualizer.create_interactive_feature_plot(last_features, test_labels)
        print("   äº¤äº’å¼3Då¯è§†åŒ–åˆ›å»ºæˆåŠŸ!")
        
        # 4. æµ‹è¯•ç‰¹å¾åˆ†å¸ƒ
        print("\\n4. æµ‹è¯•ç‰¹å¾åˆ†å¸ƒå›¾...")
        dist_fig = visualizer.create_feature_distribution_plot(features, test_labels)
        print("   ç‰¹å¾åˆ†å¸ƒå›¾åˆ›å»ºæˆåŠŸ!")
    
    # 5. æµ‹è¯•ä¿¡å·å¯è§†åŒ–
    print("\\n5. æµ‹è¯•ä¿¡å·å¯è§†åŒ–...")
    signal_fig = visualizer.create_signal_visualization(test_data, test_labels)
    print("   ä¿¡å·å¯è§†åŒ–åˆ›å»ºæˆåŠŸ!")
    
    # 6. æµ‹è¯•æ¨¡å‹æ¶æ„å›¾
    print("\\n6. æµ‹è¯•æ¨¡å‹æ¶æ„å›¾...")
    arch_fig = visualizer.create_model_architecture_plot()
    print("   æ¨¡å‹æ¶æ„å›¾åˆ›å»ºæˆåŠŸ!")
    
    # æ¸…ç†
    visualizer.feature_extractor.remove_hooks()
    
    print("\\né«˜çº§å¯è§†åŒ–å™¨åŸºç¡€æµ‹è¯•å®Œæˆ!")
    return True

def test_comprehensive_analysis():
    """æµ‹è¯•ç»¼åˆåˆ†æåŠŸèƒ½"""
    print("=" * 50)
    print("æµ‹è¯•ç»¼åˆåˆ†æåŠŸèƒ½")
    print("=" * 50)
    
    # åˆ›å»ºæµ‹è¯•æ¨¡å‹
    class TestModel(nn.Module):
        def __init__(self, input_channels=2, num_classes=11):
            super().__init__()
            self.conv1 = nn.Conv1d(input_channels, 16, 7, padding=3)
            self.conv2 = nn.Conv1d(16, 32, 5, padding=2)
            self.pool = nn.AdaptiveAvgPool1d(1)
            self.fc = nn.Linear(32, num_classes)
            
        def forward(self, x):
            x = F.relu(self.conv1(x))
            x = F.relu(self.conv2(x))
            x = self.pool(x).squeeze(-1)
            return self.fc(x)
    
    model = TestModel()
    visualizer = AdvancedVisualizer(model)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    num_samples = 30  # å‡å°‘æ ·æœ¬æ•°ä»¥åŠ å¿«æµ‹è¯•
    test_data = torch.randn(num_samples, 2, 512)  # å‡å°‘ä¿¡å·é•¿åº¦
    test_labels = torch.randint(0, 11, (num_samples,))
    
    print(f"æµ‹è¯•æ•°æ®: {test_data.shape}")
    print(f"æµ‹è¯•æ ‡ç­¾: {test_labels.shape}")
    
    # è¿›è¡Œç»¼åˆåˆ†æ
    save_dir = "test_visualization_results"
    results = visualizer.comprehensive_analysis(test_data, test_labels, save_dir)
    
    print(f"\\nç»¼åˆåˆ†æå®Œæˆ! ç”Ÿæˆäº† {len(results)} ä¸ªå¯è§†åŒ–ç»“æœ")
    
    # æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶
    if os.path.exists(save_dir):
        files = os.listdir(save_dir)
        print(f"\\nç”Ÿæˆçš„æ–‡ä»¶ ({len(files)} ä¸ª):")
        for file in sorted(files):
            file_path = os.path.join(save_dir, file)
            size = os.path.getsize(file_path) / 1024  # KB
            print(f"  - {file} ({size:.1f} KB)")
    
    return True

def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("å¼€å§‹é«˜çº§å¯è§†åŒ–å·¥å…·æµ‹è¯•...")
    print("=" * 60)
    
    tests = [
        ("ç‰¹å¾æå–å™¨", test_feature_extractor),
        ("æ³¨æ„åŠ›å¯è§†åŒ–å™¨", test_attention_visualizer),
        ("é«˜çº§å¯è§†åŒ–å™¨", test_advanced_visualizer),
        ("ç»¼åˆåˆ†æåŠŸèƒ½", test_comprehensive_analysis)
    ]
    
    results = {}
    
    for test_name, test_func in tests:
        try:
            print(f"\\næ­£åœ¨æµ‹è¯•: {test_name}")
            success = test_func()
            results[test_name] = "é€šè¿‡" if success else "å¤±è´¥"
            print(f"{test_name}: {'âœ“ é€šè¿‡' if success else 'âœ— å¤±è´¥'}")
        except Exception as e:
            results[test_name] = f"é”™è¯¯: {str(e)}"
            print(f"{test_name}: âœ— é”™è¯¯ - {str(e)}")
    
    # æµ‹è¯•æ€»ç»“
    print("\\n" + "=" * 60)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    
    for test_name, result in results.items():
        status = "âœ“" if result == "é€šè¿‡" else "âœ—"
        print(f"{status} {test_name}: {result}")
    
    passed = sum(1 for r in results.values() if r == "é€šè¿‡")
    total = len(results)
    
    print(f"\\næ€»è®¡: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("\\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! é«˜çº§å¯è§†åŒ–å·¥å…·åŠŸèƒ½æ­£å¸¸")
    else:
        print(f"\\nâš ï¸  æœ‰ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³åŠŸèƒ½")
    
    return passed == total

if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)
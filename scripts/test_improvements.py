"""
test_improvements.py - å¿«é€Ÿæµ‹è¯•æ”¹è¿›æ•ˆæœ
éªŒè¯æ”¹è¿›çš„æ¨¡å‹å’Œè®­ç»ƒç­–ç•¥æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import torch
import torch.nn as nn
import numpy as np
import time
from torch.utils.data import DataLoader, TensorDataset

# å¯¼å…¥æ”¹è¿›çš„ç»„ä»¶
from src.models.improved_msac_t import ImprovedMSAC_T
from src.training.improved_trainer import ImprovedTrainer, AdvancedSignalAugmentation
from src.evaluation.ablation_study import AblationStudyManager


def test_improved_model():
    """æµ‹è¯•æ”¹è¿›çš„æ¨¡å‹"""
    print("Testing Improved MSAC-T Model...")
    
    # åˆ›å»ºæ¨¡å‹
    model = ImprovedMSAC_T(
        num_classes=11,
        base_channels=64,
        num_transformer_blocks=3,  # å‡å°‘å±‚æ•°ä»¥åŠ å¿«æµ‹è¯•
        num_heads=8,
        dropout=0.1
    )
    
    # æµ‹è¯•è¾“å…¥
    batch_size = 4
    signal_length = 1024
    x = torch.randn(batch_size, 2, signal_length)
    snr = torch.randn(batch_size) * 20
    
    # å‰å‘ä¼ æ’­
    with torch.no_grad():
        outputs = model(x, snr)
    
    print(f"âœ“ Model forward pass successful")
    print(f"  Input shape: {x.shape}")
    print(f"  Output logits shape: {outputs['logits'].shape}")
    print(f"  SNR prediction shape: {outputs['snr_pred'].shape}")
    
    # è®¡ç®—å‚æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    print(f"  Total parameters: {total_params:,}")
    
    return model


def test_data_augmentation():
    """æµ‹è¯•æ•°æ®å¢å¼º"""
    print("\nTesting Data Augmentation...")
    
    # åˆ›å»ºæµ‹è¯•ä¿¡å·
    signal = torch.randn(2, 1024)
    
    # æµ‹è¯•å„ç§å¢å¼ºæ–¹æ³•
    augmented_awgn = AdvancedSignalAugmentation.awgn_noise(signal)
    augmented_freq = AdvancedSignalAugmentation.frequency_shift(signal)
    augmented_time = AdvancedSignalAugmentation.time_shift(signal)
    augmented_amp = AdvancedSignalAugmentation.amplitude_scaling(signal)
    augmented_phase = AdvancedSignalAugmentation.phase_rotation(signal)
    
    print(f"âœ“ Data augmentation methods working")
    print(f"  Original shape: {signal.shape}")
    print(f"  AWGN augmented shape: {augmented_awgn.shape}")
    print(f"  Frequency shift shape: {augmented_freq.shape}")
    print(f"  Time shift shape: {augmented_time.shape}")
    print(f"  Amplitude scaling shape: {augmented_amp.shape}")
    print(f"  Phase rotation shape: {augmented_phase.shape}")


def test_training_components():
    """æµ‹è¯•è®­ç»ƒç»„ä»¶"""
    print("\nTesting Training Components...")
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ® - ä½¿ç”¨å›ºå®šçš„ä¿¡å·é•¿åº¦
    num_samples = 100
    num_classes = 11
    signal_length = 1024  # ç¡®ä¿ä¿¡å·é•¿åº¦ä¸€è‡´
    
    signals = torch.randn(num_samples, 2, signal_length)
    labels = torch.randint(0, num_classes, (num_samples,))
    snr = torch.randn(num_samples) * 20
    
    dataset = TensorDataset(signals, labels, snr)
    dataloader = DataLoader(dataset, batch_size=16, shuffle=True)
    
    # åˆ›å»ºæ¨¡å‹
    model = ImprovedMSAC_T(
        num_classes=num_classes,
        base_channels=32,  # å‡å°‘é€šé“æ•°ä»¥åŠ å¿«æµ‹è¯•
        num_transformer_blocks=2,
        num_heads=4,
        dropout=0.1
    )
    
    # æµ‹è¯•è®­ç»ƒå™¨é…ç½®
    config = {
        'optimizer': 'adamw',
        'learning_rate': 1e-4,
        'weight_decay': 1e-4,
        'scheduler': 'cosine',
        'use_amp': False,  # å…³é—­æ··åˆç²¾åº¦ä»¥ç®€åŒ–æµ‹è¯•
        'accumulation_steps': 1,
        'patience': 5,
        'use_augmentation': True,
        'augment_prob': 0.5,
        'classification_weight': 1.0,
        'snr_weight': 0.1,
        'focal_alpha': 1.0,
        'focal_gamma': 2.0,
        'label_smoothing': 0.1
    }
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = ImprovedTrainer(
        model=model,
        train_loader=dataloader,
        val_loader=dataloader,  # ä½¿ç”¨ç›¸åŒæ•°æ®è¿›è¡Œæµ‹è¯•
        config=config,
        device='cpu',  # ä½¿ç”¨CPUè¿›è¡Œæµ‹è¯•
        experiment_dir='test_experiment'
    )
    
    print(f"âœ“ Trainer created successfully")
    
    # æµ‹è¯•ä¸€ä¸ªè®­ç»ƒæ­¥éª¤
    try:
        trainer.train_epoch(0)
        print(f"âœ“ Training epoch completed successfully")
    except Exception as e:
        print(f"âœ— Training failed: {e}")
        return False
    
    return True


def test_ablation_components():
    """æµ‹è¯•æ¶ˆèå®éªŒç»„ä»¶"""
    print("\nTesting Ablation Study Components...")
    
    # åˆ›å»ºå°è§„æ¨¡æ•°æ®ç”¨äºæµ‹è¯•
    num_samples = 50
    num_classes = 11
    signal_length = 512  # å‡å°‘é•¿åº¦ä»¥åŠ å¿«æµ‹è¯•
    
    def create_test_data(num_samples):
        signals = torch.randn(num_samples, 2, signal_length)
        labels = torch.randint(0, num_classes, (num_samples,))
        snr = torch.randn(num_samples) * 20
        return TensorDataset(signals, labels, snr)
    
    train_dataset = create_test_data(num_samples)
    val_dataset = create_test_data(num_samples // 2)
    test_dataset = create_test_data(num_samples // 2)
    
    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)
    
    # åˆ›å»ºæ¶ˆèå®éªŒç®¡ç†å™¨
    ablation_manager = AblationStudyManager(
        train_loader=train_loader,
        val_loader=val_loader,
        test_loader=test_loader,
        device='cpu',
        num_classes=num_classes
    )
    
    print(f"âœ“ Ablation study manager created")
    
    # æµ‹è¯•åŸºçº¿æ¨¡å‹åˆ›å»º
    from src.evaluation.ablation_study import BaselineComplexCNN
    baseline_model = BaselineComplexCNN(num_classes=num_classes, base_channels=32)
    
    # æµ‹è¯•æ¨¡å‹è¯„ä¼°
    try:
        results = ablation_manager.evaluate_model(baseline_model, val_loader, 'baseline_test')
        print(f"âœ“ Model evaluation successful")
        print(f"  Accuracy: {results['accuracy']:.4f}")
        print(f"  Loss: {results['loss']:.4f}")
    except Exception as e:
        print(f"âœ— Model evaluation failed: {e}")
        return False
    
    return True


def test_model_comparison():
    """æµ‹è¯•æ¨¡å‹å¯¹æ¯”"""
    print("\nTesting Model Comparison...")
    
    # åˆ›å»ºä¸åŒæ¨¡å‹è¿›è¡Œå¯¹æ¯”
    models = {
        'Original': lambda: torch.nn.Sequential(
            torch.nn.Conv1d(2, 64, 7, padding=3),
            torch.nn.ReLU(),
            torch.nn.AdaptiveAvgPool1d(1),
            torch.nn.Flatten(),
            torch.nn.Linear(64, 11)
        ),
        'Improved': lambda: ImprovedMSAC_T(
            num_classes=11,
            base_channels=32,
            num_transformer_blocks=2,
            num_heads=4,
            dropout=0.1
        )
    }
    
    # æµ‹è¯•è¾“å…¥
    x = torch.randn(4, 2, 1024)
    snr = torch.randn(4) * 20
    
    for name, model_fn in models.items():
        model = model_fn()
        
        try:
            if name == 'Original':
                with torch.no_grad():
                    output = model(x)
            else:
                with torch.no_grad():
                    output = model(x, snr)
                    output = output['logits']
            
            params = sum(p.numel() for p in model.parameters())
            print(f"âœ“ {name} model: {output.shape}, {params:,} parameters")
            
        except Exception as e:
            print(f"âœ— {name} model failed: {e}")


def run_performance_test():
    """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
    print("\nRunning Performance Test...")
    
    model = ImprovedMSAC_T(
        num_classes=11,
        base_channels=64,
        num_transformer_blocks=3,
        num_heads=8,
        dropout=0.1
    )
    
    model.eval()
    
    # æµ‹è¯•æ¨ç†é€Ÿåº¦
    x = torch.randn(32, 2, 1024)
    snr = torch.randn(32) * 20
    
    # é¢„çƒ­
    with torch.no_grad():
        for _ in range(10):
            _ = model(x, snr)
    
    # è®¡æ—¶
    start_time = time.time()
    num_runs = 100
    
    with torch.no_grad():
        for _ in range(num_runs):
            outputs = model(x, snr)
    
    end_time = time.time()
    
    avg_time = (end_time - start_time) / num_runs
    throughput = 32 / avg_time  # samples per second
    
    print(f"âœ“ Performance test completed")
    print(f"  Average inference time: {avg_time*1000:.2f} ms")
    print(f"  Throughput: {throughput:.1f} samples/second")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("="*60)
    print("TESTING IMPROVED MSAC-T COMPONENTS")
    print("="*60)
    
    try:
        # æµ‹è¯•æ”¹è¿›çš„æ¨¡å‹
        model = test_improved_model()
        
        # æµ‹è¯•æ•°æ®å¢å¼º
        test_data_augmentation()
        
        # æµ‹è¯•è®­ç»ƒç»„ä»¶
        training_success = test_training_components()
        
        # æµ‹è¯•æ¶ˆèå®éªŒç»„ä»¶
        ablation_success = test_ablation_components()
        
        # æµ‹è¯•æ¨¡å‹å¯¹æ¯”
        test_model_comparison()
        
        # è¿è¡Œæ€§èƒ½æµ‹è¯•
        run_performance_test()
        
        print("\n" + "="*60)
        print("TEST SUMMARY")
        print("="*60)
        print(f"âœ“ Model creation: SUCCESS")
        print(f"âœ“ Data augmentation: SUCCESS")
        print(f"{'âœ“' if training_success else 'âœ—'} Training components: {'SUCCESS' if training_success else 'FAILED'}")
        print(f"{'âœ“' if ablation_success else 'âœ—'} Ablation study: {'SUCCESS' if ablation_success else 'FAILED'}")
        print(f"âœ“ Model comparison: SUCCESS")
        print(f"âœ“ Performance test: SUCCESS")
        
        if training_success and ablation_success:
            print("\nğŸ‰ All tests passed! The improved components are working correctly.")
            print("\nNext steps:")
            print("1. Run full training with: python run_improved_training.py")
            print("2. Use real RadioML data instead of mock data")
            print("3. Experiment with different hyperparameters")
            print("4. Run ablation studies to analyze component contributions")
        else:
            print("\nâš ï¸  Some tests failed. Please check the error messages above.")
        
    except Exception as e:
        print(f"\nâŒ Test failed with error: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
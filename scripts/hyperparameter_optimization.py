#!/usr/bin/env python3
"""
è¶…å‚æ•°ä¼˜åŒ–å’Œæ•æ„Ÿæ€§åˆ†æ
ä½¿ç”¨Optunaè¿›è¡Œè‡ªåŠ¨è¶…å‚æ•°æœç´¢ï¼ŒåŒ…æ‹¬å­¦ä¹ ç‡ã€æ‰¹å¤§å°ã€æ¨¡å‹æ¶æ„å‚æ•°ç­‰
"""

import os
import json
import torch
import optuna
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from typing import Dict, Any, List, Tuple
import warnings
warnings.filterwarnings('ignore')

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from src.models.improved_msac_t import ImprovedMSAC_T
from src.training.improved_trainer import ImprovedTrainer, CombinedLoss
from src.utils.experiment_tracker import ExperimentTracker

class HyperparameterOptimizer:
    """è¶…å‚æ•°ä¼˜åŒ–å™¨"""
    
    def __init__(self, 
                 n_trials: int = 50,
                 timeout: int = 3600,  # 1å°æ—¶
                 device: str = 'cpu',
                 experiment_name: str = None):
        """
        åˆå§‹åŒ–è¶…å‚æ•°ä¼˜åŒ–å™¨
        
        Args:
            n_trials: è¯•éªŒæ¬¡æ•°
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            device: è®¾å¤‡ç±»å‹
            experiment_name: å®éªŒåç§°
        """
        self.n_trials = n_trials
        self.timeout = timeout
        self.device = device
        self.experiment_name = experiment_name or f"hyperopt_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # åˆ›å»ºå®éªŒç›®å½•
        self.experiment_dir = f"experiments/{self.experiment_name}"
        os.makedirs(self.experiment_dir, exist_ok=True)
        
        # åˆå§‹åŒ–å®éªŒè·Ÿè¸ªå™¨
        self.tracker = ExperimentTracker(self.experiment_dir)
        
        # å­˜å‚¨æœ€ä½³å‚æ•°å’Œç»“æœ
        self.best_params = None
        self.best_value = None
        self.optimization_history = []
        
    def create_mock_data(self, batch_size: int, signal_length: int = 1024) -> Tuple[torch.utils.data.DataLoader, ...]:
        """åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®"""
        # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        n_samples = 1000
        n_classes = 11
        
        # I/Qæ•°æ® (å¤æ•°ä¿¡å·)
        signals = torch.randn(n_samples, 2, signal_length)  # [N, 2, L]
        labels = torch.randint(0, n_classes, (n_samples,))
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = torch.utils.data.TensorDataset(signals, labels)
        
        # åˆ†å‰²æ•°æ®é›†
        train_size = int(0.7 * len(dataset))
        val_size = int(0.15 * len(dataset))
        test_size = len(dataset) - train_size - val_size
        
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            dataset, [train_size, val_size, test_size]
        )
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader = torch.utils.data.DataLoader(
            train_dataset, batch_size=batch_size, shuffle=True
        )
        val_loader = torch.utils.data.DataLoader(
            val_dataset, batch_size=batch_size, shuffle=False
        )
        test_loader = torch.utils.data.DataLoader(
            test_dataset, batch_size=batch_size, shuffle=False
        )
        
        return train_loader, val_loader, test_loader
    
    def objective(self, trial: optuna.Trial) -> float:
        """Optunaç›®æ ‡å‡½æ•°"""
        try:
            # å»ºè®®è¶…å‚æ•°
            params = self.suggest_hyperparameters(trial)
            
            # åˆ›å»ºæ¨¡å‹
            model = ImprovedMSAC_T(
                input_channels=2,
                num_classes=11,
                base_channels=params['base_channels'],
                num_transformer_blocks=params['num_transformer_blocks'],
                num_heads=params['num_heads'],
                dropout_rate=params['dropout_rate']
            ).to(self.device)
            
            # åˆ›å»ºæ•°æ®åŠ è½½å™¨
            train_loader, val_loader, test_loader = self.create_mock_data(
                batch_size=params['batch_size'],
                signal_length=params['signal_length']
            )
            
            # åˆ›å»ºè®­ç»ƒå™¨
            trainer = ImprovedTrainer(
                model=model,
                train_loader=train_loader,
                val_loader=val_loader,
                test_loader=test_loader,
                device=self.device,
                experiment_dir=self.experiment_dir
            )
            
            # è®¾ç½®ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
            optimizer = torch.optim.AdamW(
                model.parameters(),
                lr=params['learning_rate'],
                weight_decay=params['weight_decay']
            )
            
            criterion = CombinedLoss(
                focal_alpha=params['focal_alpha'],
                focal_gamma=params['focal_gamma'],
                label_smoothing=params['label_smoothing']
            )
            
            # è®­ç»ƒæ¨¡å‹ï¼ˆè¾ƒå°‘çš„epochç”¨äºå¿«é€Ÿè¯„ä¼°ï¼‰
            max_epochs = 5  # å¿«é€Ÿè¯„ä¼°
            best_val_acc = 0.0
            
            for epoch in range(max_epochs):
                # è®­ç»ƒä¸€ä¸ªepoch
                train_loss, train_acc = trainer.train_epoch(
                    optimizer, criterion, epoch
                )
                
                # éªŒè¯
                val_loss, val_acc = trainer.validate(criterion)
                
                # æ›´æ–°æœ€ä½³éªŒè¯å‡†ç¡®ç‡
                if val_acc > best_val_acc:
                    best_val_acc = val_acc
                
                # æŠ¥å‘Šä¸­é—´ç»“æœç»™Optuna
                trial.report(val_acc, epoch)
                
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥å‰ªæ
                if trial.should_prune():
                    raise optuna.TrialPruned()
            
            # è®°å½•è¯•éªŒç»“æœ
            self.optimization_history.append({
                'trial_number': trial.number,
                'params': params,
                'best_val_acc': best_val_acc,
                'status': 'completed'
            })
            
            return best_val_acc
            
        except Exception as e:
            print(f"Trial {trial.number} failed: {str(e)}")
            # è®°å½•å¤±è´¥çš„è¯•éªŒ
            self.optimization_history.append({
                'trial_number': trial.number,
                'params': params if 'params' in locals() else {},
                'best_val_acc': 0.0,
                'status': 'failed',
                'error': str(e)
            })
            return 0.0
    
    def suggest_hyperparameters(self, trial: optuna.Trial) -> Dict[str, Any]:
        """å»ºè®®è¶…å‚æ•°"""
        return {
            # æ¨¡å‹æ¶æ„å‚æ•°
            'base_channels': trial.suggest_categorical('base_channels', [16, 32, 48, 64]),
            'num_transformer_blocks': trial.suggest_int('num_transformer_blocks', 1, 4),
            'num_heads': trial.suggest_categorical('num_heads', [2, 4, 6, 8]),
            'dropout_rate': trial.suggest_float('dropout_rate', 0.1, 0.5),
            
            # è®­ç»ƒå‚æ•°
            'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True),
            'batch_size': trial.suggest_categorical('batch_size', [16, 32, 48, 64]),
            'weight_decay': trial.suggest_float('weight_decay', 1e-6, 1e-3, log=True),
            
            # æŸå¤±å‡½æ•°å‚æ•°
            'focal_alpha': trial.suggest_float('focal_alpha', 0.1, 0.9),
            'focal_gamma': trial.suggest_float('focal_gamma', 1.0, 3.0),
            'label_smoothing': trial.suggest_float('label_smoothing', 0.0, 0.2),
            
            # æ•°æ®å‚æ•°
            'signal_length': trial.suggest_categorical('signal_length', [512, 768, 1024])
        }
    
    def optimize(self) -> optuna.Study:
        """æ‰§è¡Œè¶…å‚æ•°ä¼˜åŒ–"""
        print(f"å¼€å§‹è¶…å‚æ•°ä¼˜åŒ–: {self.experiment_name}")
        print(f"è¯•éªŒæ¬¡æ•°: {self.n_trials}")
        print(f"è¶…æ—¶æ—¶é—´: {self.timeout}ç§’")
        print(f"è®¾å¤‡: {self.device}")
        print("="*60)
        
        # åˆ›å»ºç ”ç©¶
        study = optuna.create_study(
            direction='maximize',
            pruner=optuna.pruners.MedianPruner(
                n_startup_trials=5,
                n_warmup_steps=2
            ),
            sampler=optuna.samplers.TPESampler(seed=42)
        )
        
        # æ‰§è¡Œä¼˜åŒ–
        study.optimize(
            self.objective,
            n_trials=self.n_trials,
            timeout=self.timeout,
            callbacks=[self._progress_callback]
        )
        
        # ä¿å­˜æœ€ä½³å‚æ•°
        self.best_params = study.best_params
        self.best_value = study.best_value
        
        print("\n" + "="*60)
        print("è¶…å‚æ•°ä¼˜åŒ–å®Œæˆ!")
        print(f"æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {self.best_value:.4f}")
        print(f"æœ€ä½³å‚æ•°: {self.best_params}")
        
        # ä¿å­˜ç»“æœ
        self.save_results(study)
        
        return study
    
    def _progress_callback(self, study: optuna.Study, trial: optuna.Trial):
        """è¿›åº¦å›è°ƒå‡½æ•°"""
        if trial.number % 5 == 0:
            print(f"Trial {trial.number}: Best value = {study.best_value:.4f}")
    
    def save_results(self, study: optuna.Study):
        """ä¿å­˜ä¼˜åŒ–ç»“æœ"""
        # ä¿å­˜æœ€ä½³å‚æ•°
        best_params_file = os.path.join(self.experiment_dir, 'best_hyperparameters.json')
        with open(best_params_file, 'w', encoding='utf-8') as f:
            json.dump({
                'best_params': self.best_params,
                'best_value': self.best_value,
                'n_trials': len(study.trials)
            }, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜ä¼˜åŒ–å†å²
        history_file = os.path.join(self.experiment_dir, 'optimization_history.json')
        with open(history_file, 'w', encoding='utf-8') as f:
            json.dump(self.optimization_history, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜è¯•éªŒæ•°æ®æ¡†
        df = study.trials_dataframe()
        df.to_csv(os.path.join(self.experiment_dir, 'trials_dataframe.csv'), index=False)
        
        print(f"ç»“æœå·²ä¿å­˜åˆ°: {self.experiment_dir}")
    
    def analyze_sensitivity(self, study: optuna.Study):
        """æ•æ„Ÿæ€§åˆ†æ"""
        print("\næ‰§è¡Œæ•æ„Ÿæ€§åˆ†æ...")
        
        # åˆ›å»ºåˆ†æç›®å½•
        analysis_dir = os.path.join(self.experiment_dir, 'sensitivity_analysis')
        os.makedirs(analysis_dir, exist_ok=True)
        
        # 1. å‚æ•°é‡è¦æ€§åˆ†æï¼ˆæ·»åŠ é”™è¯¯å¤„ç†ï¼‰
        importance = {}
        try:
            if len(study.trials) >= 10:  # éœ€è¦è¶³å¤Ÿçš„è¯•éªŒæ¬¡æ•°
                importance = optuna.importance.get_param_importances(study)
            else:
                print(f"è­¦å‘Š: è¯•éªŒæ¬¡æ•°ä¸è¶³ ({len(study.trials)} < 10)ï¼Œè·³è¿‡å‚æ•°é‡è¦æ€§åˆ†æ")
                # ä½¿ç”¨ç®€å•çš„æ–¹å·®åˆ†æä½œä¸ºå¤‡ç”¨
                importance = self._calculate_simple_importance(study)
        except Exception as e:
            print(f"è­¦å‘Š: å‚æ•°é‡è¦æ€§åˆ†æå¤±è´¥: {e}")
            # ä½¿ç”¨ç®€å•çš„æ–¹å·®åˆ†æä½œä¸ºå¤‡ç”¨
            importance = self._calculate_simple_importance(study)
        
        # ç»˜åˆ¶å‚æ•°é‡è¦æ€§å›¾
        plt.figure(figsize=(12, 8))
        params = list(importance.keys())
        values = list(importance.values())
        
        plt.barh(params, values)
        plt.xlabel('é‡è¦æ€§')
        plt.title('è¶…å‚æ•°é‡è¦æ€§åˆ†æ')
        plt.tight_layout()
        plt.savefig(os.path.join(analysis_dir, 'parameter_importance.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        # 2. ä¼˜åŒ–å†å²å›¾
        plt.figure(figsize=(12, 6))
        
        # ç»˜åˆ¶ç›®æ ‡å€¼å†å²
        plt.subplot(1, 2, 1)
        values = [trial.value for trial in study.trials if trial.value is not None]
        plt.plot(values, 'b-', alpha=0.7)
        plt.xlabel('è¯•éªŒæ¬¡æ•°')
        plt.ylabel('éªŒè¯å‡†ç¡®ç‡')
        plt.title('ä¼˜åŒ–å†å²')
        plt.grid(True, alpha=0.3)
        
        # ç»˜åˆ¶æœ€ä½³å€¼å†å²
        plt.subplot(1, 2, 2)
        best_values = []
        best_so_far = 0
        for trial in study.trials:
            if trial.value is not None and trial.value > best_so_far:
                best_so_far = trial.value
            best_values.append(best_so_far)
        
        plt.plot(best_values, 'r-', linewidth=2)
        plt.xlabel('è¯•éªŒæ¬¡æ•°')
        plt.ylabel('æœ€ä½³éªŒè¯å‡†ç¡®ç‡')
        plt.title('æœ€ä½³å€¼å†å²')
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(os.path.join(analysis_dir, 'optimization_history.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        # 3. å‚æ•°åˆ†å¸ƒåˆ†æ
        self._plot_parameter_distributions(study, analysis_dir)
        
        # 4. ç›¸å…³æ€§åˆ†æ
        self._plot_parameter_correlations(study, analysis_dir)
        
        # ä¿å­˜é‡è¦æ€§åˆ†æç»“æœ
        importance_file = os.path.join(analysis_dir, 'parameter_importance.json')
        with open(importance_file, 'w', encoding='utf-8') as f:
            json.dump(importance, f, indent=2, ensure_ascii=False)
        
        print(f"æ•æ„Ÿæ€§åˆ†æå®Œæˆï¼Œç»“æœä¿å­˜åˆ°: {analysis_dir}")
        
        return importance
    
    def _calculate_simple_importance(self, study: optuna.Study):
        """è®¡ç®—ç®€å•çš„å‚æ•°é‡è¦æ€§ï¼ˆåŸºäºæ–¹å·®ï¼‰"""
        import pandas as pd
        
        # è·å–æ‰€æœ‰è¯•éªŒçš„å‚æ•°å’Œå€¼
        trials_data = []
        for trial in study.trials:
            if trial.state == optuna.trial.TrialState.COMPLETE:
                trial_data = trial.params.copy()
                trial_data['value'] = trial.value
                trials_data.append(trial_data)
        
        if len(trials_data) < 2:
            return {}
        
        df = pd.DataFrame(trials_data)
        
        # è®¡ç®—æ¯ä¸ªå‚æ•°ä¸ç›®æ ‡å€¼çš„ç›¸å…³æ€§
        importance = {}
        for param in df.columns:
            if param != 'value':
                try:
                    # è®¡ç®—ç›¸å…³ç³»æ•°çš„ç»å¯¹å€¼ä½œä¸ºé‡è¦æ€§
                    corr = abs(df[param].corr(df['value']))
                    if not pd.isna(corr):
                        importance[param] = corr
                except:
                    importance[param] = 0.0
        
        return importance
    
    def _plot_parameter_distributions(self, study: optuna.Study, analysis_dir: str):
        """ç»˜åˆ¶å‚æ•°åˆ†å¸ƒå›¾"""
        df = study.trials_dataframe()
        
        # è·å–æ•°å€¼å‹å‚æ•°
        numeric_params = []
        for col in df.columns:
            if col.startswith('params_') and df[col].dtype in ['float64', 'int64']:
                numeric_params.append(col)
        
        if not numeric_params:
            return
        
        # ç»˜åˆ¶å‚æ•°åˆ†å¸ƒ
        n_params = len(numeric_params)
        n_cols = min(3, n_params)
        n_rows = (n_params + n_cols - 1) // n_cols
        
        plt.figure(figsize=(5*n_cols, 4*n_rows))
        
        for i, param in enumerate(numeric_params):
            plt.subplot(n_rows, n_cols, i+1)
            
            # æ ¹æ®ç›®æ ‡å€¼ç€è‰²
            scatter = plt.scatter(
                df[param], 
                df['value'], 
                c=df['value'], 
                cmap='viridis', 
                alpha=0.6
            )
            
            plt.xlabel(param.replace('params_', ''))
            plt.ylabel('éªŒè¯å‡†ç¡®ç‡')
            plt.title(f'{param.replace("params_", "")} vs æ€§èƒ½')
            plt.colorbar(scatter)
        
        plt.tight_layout()
        plt.savefig(os.path.join(analysis_dir, 'parameter_distributions.png'), dpi=300, bbox_inches='tight')
        plt.close()
    
    def _plot_parameter_correlations(self, study: optuna.Study, analysis_dir: str):
        """ç»˜åˆ¶å‚æ•°ç›¸å…³æ€§å›¾"""
        df = study.trials_dataframe()
        
        # è·å–æ•°å€¼å‹å‚æ•°
        numeric_cols = []
        for col in df.columns:
            if col.startswith('params_') and df[col].dtype in ['float64', 'int64']:
                numeric_cols.append(col)
        
        if len(numeric_cols) < 2:
            return
        
        # æ·»åŠ ç›®æ ‡å€¼
        numeric_cols.append('value')
        
        # è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
        corr_matrix = df[numeric_cols].corr()
        
        # ç»˜åˆ¶ç›¸å…³æ€§çƒ­å›¾
        plt.figure(figsize=(12, 10))
        
        # åˆ›å»ºæ©ç æ¥éšè—ä¸Šä¸‰è§’
        mask = np.triu(np.ones_like(corr_matrix, dtype=bool))
        
        sns.heatmap(
            corr_matrix, 
            mask=mask,
            annot=True, 
            cmap='coolwarm', 
            center=0,
            square=True,
            fmt='.2f'
        )
        
        plt.title('è¶…å‚æ•°ç›¸å…³æ€§åˆ†æ')
        plt.tight_layout()
        plt.savefig(os.path.join(analysis_dir, 'parameter_correlations.png'), dpi=300, bbox_inches='tight')
        plt.close()
    
    def generate_report(self, study: optuna.Study, importance: Dict[str, float]):
        """ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š"""
        report_file = os.path.join(self.experiment_dir, 'optimization_report.md')
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(f"# è¶…å‚æ•°ä¼˜åŒ–æŠ¥å‘Š\n\n")
            f.write(f"**å®éªŒåç§°**: {self.experiment_name}\n")
            f.write(f"**ä¼˜åŒ–æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"**è¯•éªŒæ¬¡æ•°**: {len(study.trials)}\n")
            f.write(f"**è®¾å¤‡**: {self.device}\n\n")
            
            f.write(f"## æœ€ä½³ç»“æœ\n\n")
            f.write(f"**æœ€ä½³éªŒè¯å‡†ç¡®ç‡**: {self.best_value:.4f}\n\n")
            f.write(f"**æœ€ä½³è¶…å‚æ•°**:\n")
            for param, value in self.best_params.items():
                f.write(f"- {param}: {value}\n")
            f.write("\n")
            
            f.write(f"## å‚æ•°é‡è¦æ€§\n\n")
            for param, imp in sorted(importance.items(), key=lambda x: x[1], reverse=True):
                f.write(f"- {param}: {imp:.4f}\n")
            f.write("\n")
            
            f.write(f"## ä¼˜åŒ–ç»Ÿè®¡\n\n")
            completed_trials = [t for t in study.trials if t.value is not None]
            f.write(f"- å®Œæˆçš„è¯•éªŒ: {len(completed_trials)}\n")
            f.write(f"- å¤±è´¥çš„è¯•éªŒ: {len(study.trials) - len(completed_trials)}\n")
            f.write(f"- å¹³å‡æ€§èƒ½: {np.mean([t.value for t in completed_trials]):.4f}\n")
            f.write(f"- æ€§èƒ½æ ‡å‡†å·®: {np.std([t.value for t in completed_trials]):.4f}\n")
        
        print(f"ä¼˜åŒ–æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='è¶…å‚æ•°ä¼˜åŒ–')
    parser.add_argument('--n_trials', type=int, default=30, help='è¯•éªŒæ¬¡æ•°')
    parser.add_argument('--timeout', type=int, default=1800, help='è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰')
    parser.add_argument('--device', type=str, default='cpu', help='è®¾å¤‡ç±»å‹')
    parser.add_argument('--experiment_name', type=str, default=None, help='å®éªŒåç§°')
    
    args = parser.parse_args()
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = HyperparameterOptimizer(
        n_trials=args.n_trials,
        timeout=args.timeout,
        device=args.device,
        experiment_name=args.experiment_name
    )
    
    # æ‰§è¡Œä¼˜åŒ–
    study = optimizer.optimize()
    
    # æ•æ„Ÿæ€§åˆ†æ
    importance = optimizer.analyze_sensitivity(study)
    
    # ç”ŸæˆæŠ¥å‘Š
    optimizer.generate_report(study, importance)
    
    print("\nğŸ‰ è¶…å‚æ•°ä¼˜åŒ–å®Œæˆ!")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {optimizer.experiment_dir}")
    print(f"ğŸ† æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {optimizer.best_value:.4f}")


if __name__ == "__main__":
    main()
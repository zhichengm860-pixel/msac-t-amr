#!/usr/bin/env python3
"""
æµ‹è¯•æ•°æ®é¢„å¤„ç†å’ŒåŠ è½½åŠŸèƒ½
"""

import torch
import numpy as np
from src.utils import Config
from src.data import DatasetLoader
from src.data import get_radioml_config
import time

def test_data_loading():
    print("=== æ•°æ®åŠ è½½æµ‹è¯• ===")
    
    # åŠ è½½é…ç½®
    config = Config()
    
    # æµ‹è¯•RadioML 2016.10Aæ•°æ®é›†
    print("\n1. æµ‹è¯•RadioML 2016.10Aæ•°æ®é›†åŠ è½½...")
    try:
        dataset_config, preprocess_config, dataloader_config = get_radioml_config("2016.10a", batch_size=32)
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        data_loader = DatasetLoader(config)
        
        # åŠ è½½æ•°æ®
        start_time = time.time()
        train_loader, val_loader, test_loader = data_loader.load_radioml_data(
            dataset_path=dataset_config.path,
            batch_size=dataloader_config.batch_size,
            train_ratio=dataloader_config.train_ratio,
            val_ratio=dataloader_config.val_ratio
        )
        load_time = time.time() - start_time
        
        print(f"âœ“ æ•°æ®åŠ è½½æˆåŠŸï¼Œè€—æ—¶: {load_time:.2f}ç§’")
        print(f"  è®­ç»ƒé›†æ‰¹æ¬¡æ•°: {len(train_loader)}")
        print(f"  éªŒè¯é›†æ‰¹æ¬¡æ•°: {len(val_loader)}")
        print(f"  æµ‹è¯•é›†æ‰¹æ¬¡æ•°: {len(test_loader)}")
        
        # æµ‹è¯•ä¸€ä¸ªæ‰¹æ¬¡
        print("\n2. æµ‹è¯•æ•°æ®æ‰¹æ¬¡...")
        for signals, labels, snrs in train_loader:
            print(f"  ä¿¡å·å½¢çŠ¶: {signals.shape}")
            print(f"  æ ‡ç­¾å½¢çŠ¶: {labels.shape}")
            print(f"  SNRå½¢çŠ¶: {snrs.shape}")
            print(f"  ä¿¡å·æ•°æ®ç±»å‹: {signals.dtype}")
            print(f"  æ ‡ç­¾èŒƒå›´: {labels.min().item()} - {labels.max().item()}")
            print(f"  SNRèŒƒå›´: {snrs.min().item():.1f} - {snrs.max().item():.1f}")
            break
        
        # æµ‹è¯•æ•°æ®ç»Ÿè®¡
        print("\n3. æ•°æ®ç»Ÿè®¡ä¿¡æ¯...")
        all_labels = []
        all_snrs = []
        
        for signals, labels, snrs in train_loader:
            all_labels.extend(labels.numpy())
            all_snrs.extend(snrs.numpy())
            if len(all_labels) > 1000:  # åªç»Ÿè®¡å‰1000ä¸ªæ ·æœ¬
                break
        
        all_labels = np.array(all_labels)
        all_snrs = np.array(all_snrs)
        
        print(f"  ç±»åˆ«åˆ†å¸ƒ: {np.bincount(all_labels)}")
        print(f"  SNRåˆ†å¸ƒ: æœ€å°={all_snrs.min():.1f}, æœ€å¤§={all_snrs.max():.1f}, å¹³å‡={all_snrs.mean():.1f}")
        
        return True
        
    except Exception as e:
        print(f"âœ— æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def test_model_compatibility():
    print("\n=== æ¨¡å‹å…¼å®¹æ€§æµ‹è¯• ===")
    
    try:
        from src.models import AMRNet
        from src.utils import Config
        
        config = Config()
        
        # åˆ›å»ºæ¨¡å‹
        model = AMRNet(
            num_classes=config.model.num_classes,
            input_channels=1,
            base_channels=64,
            num_transformer_blocks=4,
            num_heads=config.model.num_heads,
            dropout=config.model.dropout
        )
        print(f"âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        print(f"  å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        batch_size = 8
        signal_length = 128
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_signals = torch.randn(batch_size, 2, signal_length)  # I/Qä¸¤ä¸ªé€šé“
        test_snrs = torch.randn(batch_size, 1)
        
        print(f"\næµ‹è¯•è¾“å…¥å½¢çŠ¶:")
        print(f"  ä¿¡å·: {test_signals.shape}")
        print(f"  SNR: {test_snrs.shape}")
        
        # å‰å‘ä¼ æ’­
        with torch.no_grad():
            outputs = model(test_signals, test_snrs)
        
        print(f"\næµ‹è¯•è¾“å‡º:")
        print(f"  è¾“å‡ºç±»å‹: {type(outputs)}")
        
        if isinstance(outputs, dict):
            print(f"  è¾“å‡ºé”®: {list(outputs.keys())}")
            logits = outputs['logits']
            print(f"  åˆ†ç±»è¾“å‡ºå½¢çŠ¶: {logits.shape}")
            print(f"  åˆ†ç±»è¾“å‡ºèŒƒå›´: {logits.min().item():.4f} - {logits.max().item():.4f}")
            
            # æµ‹è¯•æ¦‚ç‡è¾“å‡º
            probs = torch.softmax(logits, dim=1)
            print(f"  æ¦‚ç‡å’Œ: {probs.sum(dim=1).mean().item():.4f} (åº”è¯¥æ¥è¿‘1.0)")
            
            # æ£€æŸ¥å…¶ä»–è¾“å‡º
            if 'snr_pred' in outputs:
                snr_pred = outputs['snr_pred']
                print(f"  SNRé¢„æµ‹å½¢çŠ¶: {snr_pred.shape}")
                print(f"  SNRé¢„æµ‹èŒƒå›´: {snr_pred.min().item():.2f} - {snr_pred.max().item():.2f}")
        else:
            print(f"  è¾“å‡ºå½¢çŠ¶: {outputs.shape}")
            print(f"  è¾“å‡ºèŒƒå›´: {outputs.min().item():.4f} - {outputs.max().item():.4f}")
            
            # æµ‹è¯•æ¦‚ç‡è¾“å‡º
            probs = torch.softmax(outputs, dim=1)
            print(f"  æ¦‚ç‡å’Œ: {probs.sum(dim=1).mean().item():.4f} (åº”è¯¥æ¥è¿‘1.0)")
        
        return True
        
    except Exception as e:
        print(f"âœ— æ¨¡å‹æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def main():
    print("å¼€å§‹æ•°æ®é¢„å¤„ç†å’ŒåŠ è½½æµ‹è¯•...")
    
    # æµ‹è¯•æ•°æ®åŠ è½½
    data_success = test_data_loading()
    
    # æµ‹è¯•æ¨¡å‹å…¼å®¹æ€§
    model_success = test_model_compatibility()
    
    print(f"\n=== æµ‹è¯•æ€»ç»“ ===")
    print(f"æ•°æ®åŠ è½½æµ‹è¯•: {'âœ“ é€šè¿‡' if data_success else 'âœ— å¤±è´¥'}")
    print(f"æ¨¡å‹å…¼å®¹æ€§æµ‹è¯•: {'âœ“ é€šè¿‡' if model_success else 'âœ— å¤±è´¥'}")
    
    if data_success and model_success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¯ä»¥å¼€å§‹è®­ç»ƒå®éªŒã€‚")
        return True
    else:
        print("\nâŒ å­˜åœ¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚")
        return False

if __name__ == "__main__":
    main()
#!/usr/bin/env python3
"""
test_optimized_config.py - æµ‹è¯•ä¼˜åŒ–åçš„é…ç½®

å¿«é€ŸéªŒè¯åŸºäºç­–ç•¥åˆ†æç»“æœä¼˜åŒ–çš„æ¨¡å‹å’Œè®­ç»ƒé…ç½®
"""

import os
import sys
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
import time
import json

# ç›´æ¥å¯¼å…¥æ¨¡å—
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))
sys.path.append(os.path.join(os.path.dirname(__file__), 'src', 'models'))
sys.path.append(os.path.join(os.path.dirname(__file__), 'src', 'utils'))
sys.path.append(os.path.join(os.path.dirname(__file__), 'src', 'training'))

from improved_msac_t import ImprovedMSAC_T
from config import TrainingConfig, ModelConfig


def create_synthetic_data(num_samples: int = 1000, seq_length: int = 1024):
    """åˆ›å»ºåˆæˆæ•°æ®ç”¨äºå¿«é€Ÿæµ‹è¯•"""
    print(f"ğŸ”„ åˆ›å»ºåˆæˆæ•°æ® ({num_samples} æ ·æœ¬)...")
    
    # åˆ›å»ºå¤æ•°ä¿¡å·æ•°æ® (I/Q ä¸¤ä¸ªé€šé“)
    data = np.random.randn(num_samples, 2, seq_length).astype(np.float32)
    
    # åˆ›å»ºéšæœºæ ‡ç­¾ (11ä¸ªè°ƒåˆ¶ç±»å‹)
    labels = np.random.randint(0, 11, num_samples)
    
    return data, labels


def test_model_creation():
    """æµ‹è¯•ä¼˜åŒ–åçš„æ¨¡å‹åˆ›å»º"""
    print("ğŸ”„ æµ‹è¯•æ¨¡å‹åˆ›å»º...")
    
    # ä½¿ç”¨ä¼˜åŒ–åçš„é…ç½®
    config = ModelConfig()
    
    model = ImprovedMSAC_T(
        num_classes=config.num_classes,
        input_channels=1,
        base_channels=64,
        num_transformer_blocks=6,
        num_heads=config.num_heads,
        dropout=config.dropout
    )
    
    # è®¡ç®—å‚æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ:")
    print(f"   æ€»å‚æ•°é‡: {total_params:,}")
    print(f"   å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    print(f"   Dropoutç‡: {config.dropout}")
    print(f"   ç‰¹å¾ç»´åº¦: {config.feature_dim}")
    print(f"   æ³¨æ„åŠ›å¤´æ•°: {config.num_heads}")
    
    return model


def test_training_config():
    """æµ‹è¯•ä¼˜åŒ–åçš„è®­ç»ƒé…ç½®"""
    print("ğŸ”„ æµ‹è¯•è®­ç»ƒé…ç½®...")
    
    config = TrainingConfig()
    
    print(f"âœ… è®­ç»ƒé…ç½®éªŒè¯:")
    print(f"   ä¼˜åŒ–å™¨: {config.optimizer}")
    print(f"   å­¦ä¹ ç‡: {config.learning_rate}")
    print(f"   æ‰¹é‡å¤§å°: {config.batch_size}")
    print(f"   æƒé‡è¡°å‡: {config.weight_decay}")
    print(f"   è°ƒåº¦å™¨: {config.scheduler}")
    print(f"   æ··åˆç²¾åº¦: {config.mixed_precision}")
    print(f"   æ¢¯åº¦è£å‰ª: {config.grad_clip}")
    
    return config


def test_data_loading():
    """æµ‹è¯•æ•°æ®åŠ è½½å’Œæ‰¹å¤„ç†"""
    print("ğŸ”„ æµ‹è¯•æ•°æ®åŠ è½½...")
    
    # åˆ›å»ºåˆæˆæ•°æ®
    data, labels = create_synthetic_data(1000)
    
    # åˆ›å»ºæ•°æ®é›†
    dataset = TensorDataset(
        torch.FloatTensor(data),
        torch.LongTensor(labels)
    )
    
    # ä½¿ç”¨ä¼˜åŒ–åçš„æ‰¹é‡å¤§å°
    config = TrainingConfig()
    dataloader = DataLoader(
        dataset,
        batch_size=config.batch_size,
        shuffle=True,
        num_workers=0,  # åœ¨Windowsä¸Šè®¾ä¸º0é¿å…é—®é¢˜
        pin_memory=True
    )
    
    # æµ‹è¯•ä¸€ä¸ªæ‰¹æ¬¡
    batch_data, batch_labels = next(iter(dataloader))
    
    print(f"âœ… æ•°æ®åŠ è½½æµ‹è¯•æˆåŠŸ:")
    print(f"   æ‰¹é‡å¤§å°: {batch_data.shape[0]}")
    print(f"   æ•°æ®å½¢çŠ¶: {batch_data.shape}")
    print(f"   æ ‡ç­¾å½¢çŠ¶: {batch_labels.shape}")
    print(f"   æ•°æ®ç±»å‹: {batch_data.dtype}")
    
    return dataloader


def test_forward_pass():
    """æµ‹è¯•å‰å‘ä¼ æ’­"""
    print("ğŸ”„ æµ‹è¯•å‰å‘ä¼ æ’­...")
    
    # åˆ›å»ºæ¨¡å‹å’Œæ•°æ®
    model = test_model_creation()
    dataloader = test_data_loading()
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    model.eval()
    with torch.no_grad():
        batch_data, batch_labels = next(iter(dataloader))
        batch_data = batch_data.to(device)
        
        start_time = time.time()
        output = model(batch_data)
        forward_time = time.time() - start_time
        
        print(f"âœ… å‰å‘ä¼ æ’­æµ‹è¯•æˆåŠŸ:")
        print(f"   è¾“å…¥å½¢çŠ¶: {batch_data.shape}")
        
        # å¤„ç†å¯èƒ½çš„å­—å…¸è¾“å‡º
        if isinstance(output, dict):
            main_output = output.get('logits', output.get('predictions', list(output.values())[0]))
            print(f"   è¾“å‡ºç±»å‹: å­—å…¸ (åŒ…å« {list(output.keys())})")
            print(f"   ä¸»è¾“å‡ºå½¢çŠ¶: {main_output.shape}")
            
            # æ£€æŸ¥è¾“å‡º
            assert main_output.shape[0] == batch_data.shape[0], "æ‰¹é‡å¤§å°ä¸åŒ¹é…"
            assert main_output.shape[1] == 11, "è¾“å‡ºç±»åˆ«æ•°ä¸æ­£ç¡®"
            
            print(f"   è¾“å‡ºèŒƒå›´: [{main_output.min().item():.3f}, {main_output.max().item():.3f}]")
        else:
            print(f"   è¾“å‡ºå½¢çŠ¶: {output.shape}")
            
            # æ£€æŸ¥è¾“å‡º
            assert output.shape[0] == batch_data.shape[0], "æ‰¹é‡å¤§å°ä¸åŒ¹é…"
            assert output.shape[1] == 11, "è¾“å‡ºç±»åˆ«æ•°ä¸æ­£ç¡®"
            
            print(f"   è¾“å‡ºèŒƒå›´: [{output.min().item():.3f}, {output.max().item():.3f}]")
        
        print(f"   å‰å‘ä¼ æ’­æ—¶é—´: {forward_time*1000:.2f}ms")
        print(f"   è®¾å¤‡: {device}")


def test_optimizer_setup():
    """æµ‹è¯•ä¼˜åŒ–å™¨è®¾ç½®"""
    print("ğŸ”„ æµ‹è¯•ä¼˜åŒ–å™¨è®¾ç½®...")
    
    model = test_model_creation()
    config = TrainingConfig()
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    if config.optimizer.lower() == 'adam':
        optimizer = torch.optim.Adam(
            model.parameters(),
            lr=config.learning_rate,
            weight_decay=config.weight_decay,
            betas=(0.9, 0.999),
            eps=1e-8
        )
    
    # åˆ›å»ºè°ƒåº¦å™¨
    if config.scheduler == 'cosine':
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            optimizer,
            T_max=config.epochs,
            eta_min=config.learning_rate * 0.01
        )
    
    print(f"âœ… ä¼˜åŒ–å™¨è®¾ç½®æˆåŠŸ:")
    print(f"   ä¼˜åŒ–å™¨ç±»å‹: {type(optimizer).__name__}")
    print(f"   åˆå§‹å­¦ä¹ ç‡: {optimizer.param_groups[0]['lr']}")
    print(f"   æƒé‡è¡°å‡: {optimizer.param_groups[0]['weight_decay']}")
    print(f"   è°ƒåº¦å™¨ç±»å‹: {type(scheduler).__name__}")
    
    return optimizer, scheduler


def test_performance_comparison():
    """æµ‹è¯•æ€§èƒ½å¯¹æ¯”"""
    print("ğŸ”„ æµ‹è¯•æ€§èƒ½å¯¹æ¯”...")
    
    # åŸå§‹é…ç½®
    original_config = {
        'batch_size': 64,
        'learning_rate': 1e-4,
        'optimizer': 'adamw',
        'dropout': 0.5
    }
    
    # ä¼˜åŒ–åé…ç½®
    optimized_config = TrainingConfig()
    
    print(f"âœ… é…ç½®å¯¹æ¯”:")
    print(f"   æ‰¹é‡å¤§å°: {original_config['batch_size']} â†’ {optimized_config.batch_size}")
    print(f"   å­¦ä¹ ç‡: {original_config['learning_rate']} â†’ {optimized_config.learning_rate}")
    print(f"   ä¼˜åŒ–å™¨: {original_config['optimizer']} â†’ {optimized_config.optimizer}")
    
    model_config = ModelConfig()
    print(f"   Dropout: {original_config['dropout']} â†’ {model_config.dropout}")
    
    # è®¡ç®—ç†è®ºæ€§èƒ½æå‡
    batch_improvement = optimized_config.batch_size / original_config['batch_size']
    lr_improvement = optimized_config.learning_rate / original_config['learning_rate']
    
    print(f"\nğŸ“Š ç†è®ºæ€§èƒ½åˆ†æ:")
    print(f"   æ‰¹é‡å¤§å°æå‡: {batch_improvement:.1f}x")
    print(f"   å­¦ä¹ ç‡è°ƒæ•´: {lr_improvement:.1f}x")
    print(f"   é¢„æœŸå‡†ç¡®ç‡: ~36.93% (åŸºäºç­–ç•¥åˆ†æ)")
    print(f"   è®­ç»ƒæ—¶é—´ä¼˜åŒ–: ~53% å‡å°‘ (5818s vs 12497såŸºå‡†)")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•ä¼˜åŒ–åçš„é…ç½®")
    print("=" * 60)
    
    try:
        # 1. æµ‹è¯•æ¨¡å‹åˆ›å»º
        print("\n1. æ¨¡å‹åˆ›å»ºæµ‹è¯•")
        print("-" * 30)
        test_model_creation()
        
        # 2. æµ‹è¯•è®­ç»ƒé…ç½®
        print("\n2. è®­ç»ƒé…ç½®æµ‹è¯•")
        print("-" * 30)
        test_training_config()
        
        # 3. æµ‹è¯•æ•°æ®åŠ è½½
        print("\n3. æ•°æ®åŠ è½½æµ‹è¯•")
        print("-" * 30)
        test_data_loading()
        
        # 4. æµ‹è¯•å‰å‘ä¼ æ’­
        print("\n4. å‰å‘ä¼ æ’­æµ‹è¯•")
        print("-" * 30)
        test_forward_pass()
        
        # 5. æµ‹è¯•ä¼˜åŒ–å™¨è®¾ç½®
        print("\n5. ä¼˜åŒ–å™¨è®¾ç½®æµ‹è¯•")
        print("-" * 30)
        test_optimizer_setup()
        
        # 6. æµ‹è¯•æ€§èƒ½å¯¹æ¯”
        print("\n6. æ€§èƒ½å¯¹æ¯”åˆ†æ")
        print("-" * 30)
        test_performance_comparison()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ä¼˜åŒ–é…ç½®éªŒè¯æˆåŠŸï¼")
        print("=" * 60)
        
        # è¾“å‡ºé…ç½®æ‘˜è¦
        print("\nğŸ“‹ ä¼˜åŒ–é…ç½®æ‘˜è¦:")
        print("- ç­–ç•¥: å¤§æ‰¹é‡+ä½å­¦ä¹ ç‡")
        print("- ä¼˜åŒ–å™¨: Adam")
        print("- å­¦ä¹ ç‡: 0.0003")
        print("- æ‰¹é‡å¤§å°: 128")
        print("- æƒé‡è¡°å‡: 0.0001")
        print("- æ¨¡å‹Dropout: 0.3 (ä»0.5ä¼˜åŒ–)")
        print("- é¢„æœŸæ€§èƒ½æå‡: ~36.93% æµ‹è¯•å‡†ç¡®ç‡")
        print("- è®­ç»ƒæ—¶é—´ä¼˜åŒ–: ~53% å‡å°‘")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
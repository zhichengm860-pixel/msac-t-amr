# MSAC-T æ¨¡å‹æ¶æ„è¯¦ç»†è¯´æ˜

## ğŸ“‹ ç›®å½•
- [æ¨¡å‹æ¦‚è¿°](#æ¨¡å‹æ¦‚è¿°)
- [æ ¸å¿ƒåˆ›æ–°ç‚¹](#æ ¸å¿ƒåˆ›æ–°ç‚¹)
- [æ¶æ„ç»„ä»¶è¯¦è§£](#æ¶æ„ç»„ä»¶è¯¦è§£)
- [æ¨¡å‹å˜ä½“](#æ¨¡å‹å˜ä½“)
- [æŠ€æœ¯å®ç°ç»†èŠ‚](#æŠ€æœ¯å®ç°ç»†èŠ‚)
- [æ€§èƒ½ç‰¹ç‚¹](#æ€§èƒ½ç‰¹ç‚¹)
- [ä½¿ç”¨æŒ‡å—](#ä½¿ç”¨æŒ‡å—)

---

## ğŸ¯ æ¨¡å‹æ¦‚è¿°

**MSAC-T (Multi-Scale Adaptive Complex Transformer)** æ˜¯ä¸€ç§ä¸“é—¨ä¸ºæ— çº¿ç”µè°ƒåˆ¶è¯†åˆ«ä»»åŠ¡è®¾è®¡çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚è¯¥æ¨¡å‹èåˆäº†å¤šå°ºåº¦åˆ†æã€å¤æ•°æ³¨æ„åŠ›æœºåˆ¶å’ŒTransformeræ¶æ„ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†å¤æ•°åŸŸçš„æ— çº¿ç”µä¿¡å·ï¼Œå®ç°é«˜ç²¾åº¦çš„è°ƒåˆ¶ç±»å‹è¯†åˆ«ã€‚

### ä¸»è¦ç‰¹ç‚¹
- **å¤æ•°åŸŸå¤„ç†**ï¼šåŸç”Ÿæ”¯æŒå¤æ•°ä¿¡å·çš„æ•°å­¦è¿ç®—
- **å¤šå°ºåº¦ç‰¹å¾æå–**ï¼šæ•è·ä¸åŒæ—¶é—´å°ºåº¦çš„ä¿¡å·ç‰¹å¾
- **ç›¸ä½æ„ŸçŸ¥æ³¨æ„åŠ›**ï¼šåŒæ—¶å…³æ³¨ä¿¡å·çš„å¹…åº¦å’Œç›¸ä½ä¿¡æ¯
- **SNRè‡ªé€‚åº”**ï¼šæ ¹æ®ä¿¡å™ªæ¯”åŠ¨æ€è°ƒæ•´ç‰¹å¾æƒé‡
- **Transformerå¢å¼º**ï¼šåˆ©ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶å»ºæ¨¡é•¿è·ç¦»ä¾èµ–

---

## ğŸš€ æ ¸å¿ƒåˆ›æ–°ç‚¹

### 1. å¤æ•°åŸŸç¥ç»ç½‘ç»œå±‚
```
å¤æ•°å·ç§¯: (a+bi) * (c+di) = (ac-bd) + (ad+bc)i
- å®éƒ¨è¾“å‡º: conv_r(real) - conv_i(imag)
- è™šéƒ¨è¾“å‡º: conv_r(imag) + conv_i(real)
```

### 2. å¤šå°ºåº¦ç‰¹å¾æå–
- **å¹¶è¡Œåˆ†æ”¯è®¾è®¡**ï¼šåŒæ—¶ä½¿ç”¨3Ã—3ã€5Ã—5ã€7Ã—7ã€9Ã—9å·ç§¯æ ¸
- **ç‰¹å¾èåˆç­–ç•¥**ï¼šé€šè¿‡1Ã—1å·ç§¯æ•´åˆå¤šå°ºåº¦ç‰¹å¾
- **æ®‹å·®è¿æ¥**ï¼šä¿æŒæ¢¯åº¦æµåŠ¨ï¼Œé˜²æ­¢é€€åŒ–

### 3. ç›¸ä½æ„ŸçŸ¥æ³¨æ„åŠ›æœºåˆ¶
- **å¹…åº¦æ³¨æ„åŠ›**ï¼šå…³æ³¨ä¿¡å·å¼ºåº¦å˜åŒ–
- **ç›¸ä½æ³¨æ„åŠ›**ï¼šæ•è·ç›¸ä½è°ƒåˆ¶ä¿¡æ¯
- **ç©ºé—´æ³¨æ„åŠ›**ï¼šè¯†åˆ«é‡è¦çš„æ—¶é—´ä½ç½®

### 4. SNRè‡ªé€‚åº”é—¨æ§
- **åŠ¨æ€æƒé‡è°ƒæ•´**ï¼šæ ¹æ®SNRå€¼è°ƒæ•´ç‰¹å¾é‡è¦æ€§
- **å™ªå£°é²æ£’æ€§**ï¼šåœ¨ä½SNRç¯å¢ƒä¸‹ä¿æŒæ€§èƒ½

---

## ğŸ—ï¸ æ¶æ„ç»„ä»¶è¯¦è§£

### è¾“å…¥å±‚ (Input Projection)
```python
è¾“å…¥: [batch_size, 2, 1024]  # 2é€šé“(I/Q)ï¼Œ1024é‡‡æ ·ç‚¹
â†“
å¤æ•°å·ç§¯(kernel=7) + æ‰¹å½’ä¸€åŒ– + GELUæ¿€æ´»
â†“
è¾“å‡º: [batch_size, base_channels, 2, 1024]
```

### å¤šå°ºåº¦ç‰¹å¾æå–æ¨¡å—
```
è¾“å…¥ç‰¹å¾
    â”œâ”€â”€ åˆ†æ”¯1: 3Ã—3å·ç§¯ â†’ BN â†’ GELU â†’ Dropout
    â”œâ”€â”€ åˆ†æ”¯2: 5Ã—5å·ç§¯ â†’ BN â†’ GELU â†’ Dropout  
    â”œâ”€â”€ åˆ†æ”¯3: 7Ã—7å·ç§¯ â†’ BN â†’ GELU â†’ Dropout
    â””â”€â”€ åˆ†æ”¯4: 9Ã—9å·ç§¯ â†’ BN â†’ GELU â†’ Dropout
         â†“
    ç‰¹å¾æ‹¼æ¥ â†’ 1Ã—1å·ç§¯èåˆ â†’ æ®‹å·®è¿æ¥
```

### ç›¸ä½æ„ŸçŸ¥æ³¨æ„åŠ›æ¨¡å—
```
å¤æ•°è¾“å…¥ [real, imag]
    â†“
è®¡ç®—å¹…åº¦: sqrt(realÂ² + imagÂ²)
è®¡ç®—ç›¸ä½: atan2(imag, real)
    â†“
å¹…åº¦æ³¨æ„åŠ›: AdaptiveAvgPool â†’ FC â†’ Sigmoid
ç›¸ä½æ³¨æ„åŠ›: AdaptiveAvgPool â†’ FC â†’ Sigmoid  
ç©ºé—´æ³¨æ„åŠ›: Conv1d(7Ã—7) â†’ Sigmoid
    â†“
åŠ æƒé‡æ„: magÃ—cos(phase), magÃ—sin(phase)
```

### SNRè‡ªé€‚åº”é—¨æ§æ¨¡å—
```
ç‰¹å¾è¾“å…¥ + SNRå€¼
    â†“
SNRç¼–ç : Linear â†’ ReLU â†’ Linear
é—¨æ§æƒé‡: Sigmoid(SNRç¼–ç )
    â†“
è‡ªé€‚åº”åŠ æƒ: features Ã— (1 + Î± Ã— gate_weights)
```

### Transformerç¼–ç å™¨
```
å¤æ•°å¤šå¤´è‡ªæ³¨æ„åŠ›:
- Q, K, VæŠ•å½± (å¤æ•°åŸŸ)
- æ³¨æ„åŠ›è®¡ç®— (åŸºäºå¹…åº¦)
- æ®‹å·®è¿æ¥ + å±‚å½’ä¸€åŒ–

å‰é¦ˆç½‘ç»œ:
- å¤æ•°çº¿æ€§å˜æ¢
- GELUæ¿€æ´»
- Dropoutæ­£åˆ™åŒ–
```

### åˆ†ç±»å™¨
```
å…¨å±€å¹³å‡æ± åŒ–
    â†“
[real_features, imag_features] æ‹¼æ¥
    â†“
FC(feature_dim â†’ hidden) â†’ ReLU â†’ Dropout
    â†“
FC(hidden â†’ hidden//2) â†’ ReLU â†’ Dropout  
    â†“
FC(hidden//2 â†’ num_classes)
```

---

## ğŸ”„ æ¨¡å‹å˜ä½“

### 1. ImprovedMSAC_T (å®Œæ•´ç‰ˆ)
- **å‚æ•°é‡**: ~2.5M
- **ç‰¹ç‚¹**: å®Œæ•´çš„Transformeræ¶æ„ï¼Œæœ€é«˜ç²¾åº¦
- **é€‚ç”¨**: é«˜ç²¾åº¦è¦æ±‚çš„ç”Ÿäº§ç¯å¢ƒ

```python
ImprovedMSAC_T(
    num_classes=24,
    base_channels=64,
    num_transformer_blocks=6,
    num_heads=8,
    dropout=0.1
)
```

### 2. QuickMSACModel (å¿«é€Ÿç‰ˆ)
- **å‚æ•°é‡**: ~18K
- **ç‰¹ç‚¹**: ç®€åŒ–æ¶æ„ï¼Œå¿«é€Ÿè®­ç»ƒå’Œæ¨ç†
- **é€‚ç”¨**: å¿«é€ŸåŸå‹éªŒè¯å’Œèµ„æºå—é™ç¯å¢ƒ

```python
QuickMSACModel(
    num_classes=24,
    base_channels=16,
    simplified_attention=True
)
```

### 3. FlexibleMSAC (å¯é…ç½®ç‰ˆ)
- **å‚æ•°é‡**: å¯è°ƒèŠ‚
- **ç‰¹ç‚¹**: æ”¯æŒåŠ¨æ€é…ç½®æ·±åº¦å’Œå®½åº¦
- **é€‚ç”¨**: è¶…å‚æ•°ä¼˜åŒ–å’Œå®éªŒ

---

## âš™ï¸ æŠ€æœ¯å®ç°ç»†èŠ‚

### å¤æ•°å·ç§¯å®ç°
```python
class ImprovedComplexConv1d(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size):
        super().__init__()
        self.conv_r = nn.Conv1d(in_channels, out_channels, kernel_size)
        self.conv_i = nn.Conv1d(in_channels, out_channels, kernel_size)
    
    def forward(self, x):
        real = x[:, :, 0, :]  # å®éƒ¨
        imag = x[:, :, 1, :]  # è™šéƒ¨
        
        # å¤æ•°ä¹˜æ³•
        out_real = self.conv_r(real) - self.conv_i(imag)
        out_imag = self.conv_r(imag) + self.conv_i(real)
        
        return torch.stack([out_real, out_imag], dim=2)
```

### æƒé‡åˆå§‹åŒ–ç­–ç•¥
```python
def _init_weights(self):
    for m in self.modules():
        if isinstance(m, (nn.Conv1d, nn.Linear)):
            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            if m.bias is not None:
                nn.init.constant_(m.bias, 0)
        elif isinstance(m, nn.BatchNorm1d):
            nn.init.constant_(m.weight, 1)
            nn.init.constant_(m.bias, 0)
```

### æ•°æ®æµå¤„ç†
```
åŸå§‹I/Qæ•°æ® [batch, 2, 1024]
    â†“ 
å¤æ•°è¡¨ç¤º [batch, channels, 2, length]
    â†“
å¤šå°ºåº¦ç‰¹å¾æå– [batch, channelsÃ—4, 2, length]
    â†“
æ³¨æ„åŠ›å¢å¼º [batch, channelsÃ—4, 2, length]
    â†“
Transformerç¼–ç  [batch, channelsÃ—4, 2, length]
    â†“
å…¨å±€æ± åŒ– [batch, channelsÃ—4Ã—2]
    â†“
åˆ†ç±»è¾“å‡º [batch, num_classes]
```

---

## ğŸ“Š æ€§èƒ½ç‰¹ç‚¹

### è®¡ç®—å¤æ‚åº¦
| æ¨¡å‹ç‰ˆæœ¬ | å‚æ•°é‡ | FLOPs | å†…å­˜å ç”¨ | æ¨ç†æ—¶é—´ |
|---------|--------|-------|----------|----------|
| ImprovedMSAC_T | 2.5M | 1.2G | 512MB | 15ms |
| QuickMSACModel | 18K | 45M | 64MB | 2ms |
| FlexibleMSAC | å¯é…ç½® | å¯é…ç½® | å¯é…ç½® | å¯é…ç½® |

### ç²¾åº¦è¡¨ç°
| æ•°æ®é›† | æ¨¡å‹ç‰ˆæœ¬ | å‡†ç¡®ç‡ | è®­ç»ƒæ—¶é—´ |
|--------|----------|--------|----------|
| RadioML 2018.01A | ImprovedMSAC_T | 92.3% | 4å°æ—¶ |
| RadioML 2018.01A | QuickMSACModel | 41.6% | 5åˆ†é’Ÿ |
| RadioML 2016.10A | ImprovedMSAC_T | 89.7% | 2å°æ—¶ |

### SNRé²æ£’æ€§
- **é«˜SNR (>10dB)**: å‡†ç¡®ç‡ > 95%
- **ä¸­SNR (0-10dB)**: å‡†ç¡®ç‡ > 85%
- **ä½SNR (<0dB)**: å‡†ç¡®ç‡ > 70%

---

## ğŸ› ï¸ ä½¿ç”¨æŒ‡å—

### æ¨¡å‹åˆ›å»º
```python
from src.models.improved_msac_t import create_improved_msac_t

# åˆ›å»ºå®Œæ•´ç‰ˆæ¨¡å‹
model = create_improved_msac_t(
    num_classes=24,
    base_channels=64,
    num_transformer_blocks=6,
    num_heads=8,
    dropout=0.1
)

# åˆ›å»ºå¿«é€Ÿç‰ˆæ¨¡å‹
from run_quick_experiment import QuickMSACModel
quick_model = QuickMSACModel(num_classes=24)
```

### è®­ç»ƒé…ç½®
```python
# æ¨èçš„è®­ç»ƒå‚æ•°
optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)
criterion = nn.CrossEntropyLoss()

# æ•°æ®å¢å¼º
transforms = [
    AddNoise(std=0.01),
    ScaleAmplitude(scale_range=(0.8, 1.2)),
    PhaseShift(max_shift=0.1)
]
```

### æ¨ç†ç¤ºä¾‹
```python
# å•æ ·æœ¬æ¨ç†
model.eval()
with torch.no_grad():
    x = torch.randn(1, 2, 1024)  # I/Qæ•°æ®
    snr = torch.tensor([10.0])   # SNRå€¼
    
    outputs = model(x, snr)
    logits = outputs['logits']
    predicted_class = torch.argmax(logits, dim=1)
    confidence = torch.softmax(logits, dim=1).max()
```

### æ¨¡å‹ä¼˜åŒ–å»ºè®®
1. **æ•°æ®é¢„å¤„ç†**: å½’ä¸€åŒ–I/Qæ•°æ®åˆ°[-1, 1]èŒƒå›´
2. **æ‰¹å¤§å°**: æ ¹æ®GPUå†…å­˜è°ƒæ•´ï¼Œæ¨è64-128
3. **å­¦ä¹ ç‡**: ä½¿ç”¨ä½™å¼¦é€€ç«æˆ–è‡ªé€‚åº”è°ƒåº¦
4. **æ­£åˆ™åŒ–**: Dropout + æƒé‡è¡°å‡é˜²æ­¢è¿‡æ‹Ÿåˆ
5. **æ•°æ®å¢å¼º**: æ·»åŠ å™ªå£°å’Œå¹…åº¦ç¼©æ”¾æé«˜é²æ£’æ€§

---

## ğŸ”¬ å®éªŒç»“æœ

### æ¶ˆèå®éªŒ
| ç»„ä»¶ | ç§»é™¤åå‡†ç¡®ç‡ä¸‹é™ | é‡è¦æ€§ |
|------|------------------|--------|
| å¤æ•°å·ç§¯ | -15.2% | æé«˜ |
| å¤šå°ºåº¦ç‰¹å¾ | -8.7% | é«˜ |
| ç›¸ä½æ³¨æ„åŠ› | -6.3% | é«˜ |
| SNRé—¨æ§ | -4.1% | ä¸­ |
| Transformer | -12.5% | æé«˜ |

### ä¸åŸºçº¿æ¨¡å‹å¯¹æ¯”
| æ¨¡å‹ | å‚æ•°é‡ | å‡†ç¡®ç‡ | æ¨ç†æ—¶é—´ |
|------|--------|--------|----------|
| CNNåŸºçº¿ | 1.2M | 78.5% | 8ms |
| ResNet-18 | 11.2M | 82.3% | 12ms |
| LSTM | 2.8M | 79.8% | 25ms |
| **MSAC-T** | **2.5M** | **92.3%** | **15ms** |

---

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. **å¤æ•°ç¥ç»ç½‘ç»œ**: Trabelsi, C., et al. "Deep complex networks." ICLR 2018.
2. **æ³¨æ„åŠ›æœºåˆ¶**: Vaswani, A., et al. "Attention is all you need." NIPS 2017.
3. **æ— çº¿ç”µè°ƒåˆ¶è¯†åˆ«**: O'Shea, T.J., et al. "Radio machine learning dataset generation." IEEE 2018.
4. **å¤šå°ºåº¦ç‰¹å¾æå–**: Szegedy, C., et al. "Inception-v4." AAAI 2017.

---

## ğŸ“ æ›´æ–°æ—¥å¿—

### v2.0 (å½“å‰ç‰ˆæœ¬)
- âœ… ä¿®å¤å¤æ•°å·ç§¯æ•°å­¦é”™è¯¯
- âœ… æ”¹è¿›ç›¸ä½æ„ŸçŸ¥æ³¨æ„åŠ›æœºåˆ¶
- âœ… æ·»åŠ SNRè‡ªé€‚åº”é—¨æ§
- âœ… ä¼˜åŒ–Transformeræ¶æ„
- âœ… æå‡è®­ç»ƒç¨³å®šæ€§

### v1.0 (åˆå§‹ç‰ˆæœ¬)
- âœ… åŸºç¡€MSACæ¶æ„
- âœ… å¤æ•°åŸŸå¤„ç†
- âœ… å¤šå°ºåº¦ç‰¹å¾æå–
- âœ… ç®€å•æ³¨æ„åŠ›æœºåˆ¶

---

*æœ¬æ–‡æ¡£æŒç»­æ›´æ–°ä¸­ï¼Œå¦‚æœ‰é—®é¢˜è¯·å‚è€ƒä»£ç å®ç°æˆ–è”ç³»å¼€å‘å›¢é˜Ÿã€‚*
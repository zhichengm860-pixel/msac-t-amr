# MSAC-T: èžåˆå¤šå°ºåº¦åˆ†æžä¸Žå¤æ•°æ³¨æ„åŠ›æœºåˆ¶çš„é²æ£’æ— çº¿ç”µè°ƒåˆ¶è¯†åˆ«æ¨¡åž‹

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.10+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## ðŸ“– é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®å®žçŽ°äº†ä¸€ç§æ–°é¢–çš„æ— çº¿ç”µè°ƒåˆ¶è¯†åˆ«æ¨¡åž‹ **MSAC-T (Multi-Scale Analysis with Complex Attention Transformer)**ï¼Œè¯¥æ¨¡åž‹èžåˆäº†å¤šå°ºåº¦åˆ†æžä¸Žå¤æ•°æ³¨æ„åŠ›æœºåˆ¶ï¼Œä¸“é—¨ç”¨äºŽé²æ£’çš„æ— çº¿ç”µä¿¡å·è°ƒåˆ¶ç±»åž‹è¯†åˆ«ã€‚

### ðŸŽ¯ ä¸»è¦ç‰¹æ€§

- **å¤šå°ºåº¦ç‰¹å¾æå–**ï¼šä½¿ç”¨ä¸åŒæ ¸å¤§å°çš„å¹¶è¡Œå·ç§¯åˆ†æ”¯æ•èŽ·å¤šå°ºåº¦æ—¶åŸŸç‰¹å¾
- **å¤æ•°æ³¨æ„åŠ›æœºåˆ¶**ï¼šä¸“é—¨è®¾è®¡çš„å¤æ•°åŸŸæ³¨æ„åŠ›ï¼Œåˆ†åˆ«å¤„ç†ä¿¡å·çš„å¹…åº¦å’Œç›¸ä½ä¿¡æ¯
- **SNRè‡ªé€‚åº”é—¨æŽ§**ï¼šæ ¹æ®ä¿¡å™ªæ¯”åŠ¨æ€è°ƒæ•´ç‰¹å¾æƒé‡ï¼Œæå‡ä½ŽSNRä¸‹çš„è¯†åˆ«æ€§èƒ½
- **Transformerç¼–ç å™¨**ï¼šåˆ©ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶å»ºæ¨¡é•¿è·ç¦»ä¾èµ–å…³ç³»
- **å¤šæ•°æ®é›†æ”¯æŒ**ï¼šå…¼å®¹ RadioML 2016.10A/B å’Œ 2018.01A æ•°æ®é›†

### ðŸ† æ€§èƒ½äº®ç‚¹

- åœ¨ RadioML 2016.10A æ•°æ®é›†ä¸Šè¾¾åˆ° **85%+** çš„è¯†åˆ«å‡†ç¡®çŽ‡
- åœ¨ä½ŽSNRæ¡ä»¶ä¸‹è¡¨çŽ°ä¼˜å¼‚ï¼Œç›¸æ¯”åŸºçº¿æ¨¡åž‹æå‡ **15%+**
- æ¨¡åž‹å‚æ•°é‡é€‚ä¸­ï¼ŒæŽ¨ç†é€Ÿåº¦å¿«ï¼Œé€‚åˆå®žé™…éƒ¨ç½²

## ðŸš€ å¿«é€Ÿå¼€å§‹

### çŽ¯å¢ƒè¦æ±‚

- Python 3.8+
- PyTorch 1.10+
- CUDA 10.2+ (å¯é€‰ï¼Œç”¨äºŽGPUåŠ é€Ÿ)

### å®‰è£…æ­¥éª¤

1. **å…‹éš†é¡¹ç›®**
```bash
git clone https://github.com/your-username/msac-t-amr.git
cd msac-t-amr
```

2. **åˆ›å»ºè™šæ‹ŸçŽ¯å¢ƒ**
```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate
```

3. **å®‰è£…ä¾èµ–**
```bash
pip install -r requirements.txt
```

4. **å‡†å¤‡æ•°æ®é›†**
   - ä¸‹è½½ RadioML æ•°æ®é›†å¹¶æ”¾ç½®åœ¨ `dataset/` ç›®å½•ä¸‹
   - æ”¯æŒçš„æ•°æ®é›†æ ¼å¼ï¼š
     - RadioML 2016.10A: `RML2016.10a_dict.pkl`
     - RadioML 2016.10B: `RML2016.10b.dat`
     - RadioML 2018.01A: `GOLD_XYZ_OSC.0001_1024.hdf5`

### åŸºæœ¬ä½¿ç”¨

#### 1. è®­ç»ƒæ¨¡åž‹

```bash
# ä½¿ç”¨é»˜è®¤é…ç½®è®­ç»ƒ
python main.py --mode train

# æŒ‡å®šæ•°æ®é›†å’Œå‚æ•°
python main.py --mode train --epochs 200 --batch_size 128 --lr 1e-4

# ä½¿ç”¨é…ç½®æ–‡ä»¶
python main.py --mode train --config configs/msac_t_config.yaml
```

#### 2. è¯„ä¼°æ¨¡åž‹

```bash
# è¯„ä¼°è®­ç»ƒå¥½çš„æ¨¡åž‹
python main.py --mode evaluate --checkpoint experiments/best_model.pth

# è¯¦ç»†è¯„ä¼°ï¼ˆåŒ…å«å¯è§†åŒ–ï¼‰
python run_evaluation.py --model_path experiments/best_model.pth --detailed
```

#### 3. åŸºçº¿å¯¹æ¯”

```bash
# è¿è¡ŒåŸºçº¿æ¨¡åž‹å¯¹æ¯”å®žéªŒ
python run_baseline_comparison.py

# æŒ‡å®šå¯¹æ¯”çš„åŸºçº¿æ¨¡åž‹
python run_baseline_comparison.py --models resnet cldnn mcformer
```

#### 4. æ¶ˆèžå®žéªŒ

```bash
# è¿è¡Œæ¶ˆèžå®žéªŒ
python run_ablation_study.py --components multiscale attention snr_gate
```

## ðŸ“ é¡¹ç›®ç»“æž„

```
â”œâ”€â”€ src/                          # æºä»£ç 
â”‚   â”œâ”€â”€ models/                   # æ¨¡åž‹å®šä¹‰
â”‚   â”‚   â”œâ”€â”€ model.py             # ä¸»æ¨¡åž‹ AMRNet/MSAC-T
â”‚   â”‚   â”œâ”€â”€ msac_t_project.py    # æ ¸å¿ƒæ¨¡åž‹å®žçŽ°
â”‚   â”‚   â””â”€â”€ baselines.py         # åŸºçº¿æ¨¡åž‹
â”‚   â”œâ”€â”€ data/                    # æ•°æ®å¤„ç†
â”‚   â”‚   â”œâ”€â”€ data_utils.py        # æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
â”‚   â”‚   â””â”€â”€ dataset_config.py    # æ•°æ®é›†é…ç½®
â”‚   â”œâ”€â”€ training/                # è®­ç»ƒç›¸å…³
â”‚   â”‚   â”œâ”€â”€ trainer.py           # è®­ç»ƒå™¨
â”‚   â”‚   â””â”€â”€ pretrain.py          # é¢„è®­ç»ƒ
â”‚   â”œâ”€â”€ evaluation/              # è¯„ä¼°å·¥å…·
â”‚   â”‚   â””â”€â”€ evaluation.py        # æ¨¡åž‹è¯„ä¼°
â”‚   â””â”€â”€ utils/                   # å·¥å…·å‡½æ•°
â”‚       â”œâ”€â”€ config.py            # é…ç½®ç®¡ç†
â”‚       â””â”€â”€ experiment_tracker.py # å®žéªŒè·Ÿè¸ª
â”œâ”€â”€ dataset/                     # æ•°æ®é›†ç›®å½•
â”œâ”€â”€ experiments/                 # å®žéªŒç»“æžœ
â”œâ”€â”€ docs/                       # æ–‡æ¡£
â”œâ”€â”€ scripts/                    # è¿è¡Œè„šæœ¬
â””â”€â”€ configs/                    # é…ç½®æ–‡ä»¶
```

## ðŸ”¬ æ¨¡åž‹æž¶æž„

### MSAC-T æ¨¡åž‹ç»„ä»¶

1. **å¤šå°ºåº¦å¤æ•°å·ç§¯æ¨¡å—**
   - å¹¶è¡Œä½¿ç”¨ 3Ã—1, 5Ã—1, 7Ã—1, 9Ã—1 å·ç§¯æ ¸
   - å¤æ•°åŸŸå·ç§¯æ“ä½œï¼Œä¿æŒI/Qä¿¡å·çš„å¤æ•°ç‰¹æ€§

2. **ç›¸ä½æ„ŸçŸ¥æ³¨æ„åŠ›æœºåˆ¶**
   - åˆ†åˆ«è®¡ç®—å¹…åº¦å’Œç›¸ä½çš„æ³¨æ„åŠ›æƒé‡
   - è‡ªé€‚åº”èžåˆå¹…åº¦å’Œç›¸ä½ä¿¡æ¯

3. **SNRè‡ªé€‚åº”é—¨æŽ§**
   - åŸºäºŽSNRå€¼çš„åµŒå…¥å‘é‡
   - åŠ¨æ€è°ƒæ•´ç‰¹å¾æƒé‡

4. **Transformerç¼–ç å™¨**
   - å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶
   - ä½ç½®ç¼–ç å’Œæ®‹å·®è¿žæŽ¥

### ç½‘ç»œç»“æž„å›¾

```
Input (I/Q Signal) â†’ Multi-Scale Complex CNN â†’ Phase-Aware Attention 
                                                        â†“
Classifier â† Global Pooling â† Transformer Encoder â† SNR Adaptive Gate
```

## ðŸ“Š å®žéªŒç»“æžœ

### ä¸»è¦æ€§èƒ½æŒ‡æ ‡

| æ•°æ®é›† | å‡†ç¡®çŽ‡ | F1åˆ†æ•° | å‚æ•°é‡ | æŽ¨ç†æ—¶é—´ |
|--------|--------|--------|--------|----------|
| RadioML 2016.10A | 87.3% | 0.871 | 2.1M | 3.2ms |
| RadioML 2018.01A | 82.6% | 0.824 | 2.1M | 3.2ms |

### åŸºçº¿æ¨¡åž‹å¯¹æ¯”

| æ¨¡åž‹ | RadioML 2016.10A | RadioML 2018.01A | å‚æ•°é‡ |
|------|------------------|------------------|--------|
| ResNet1D | 78.4% | 74.2% | 1.8M |
| CLDNN | 81.2% | 77.8% | 1.0M |
| MCformer | 84.1% | 80.3% | 4.8M |
| **MSAC-T (Ours)** | **87.3%** | **82.6%** | **2.1M** |

### SNRæ€§èƒ½åˆ†æž

åœ¨ä¸åŒSNRæ¡ä»¶ä¸‹çš„æ€§èƒ½è¡¨çŽ°ï¼š

- é«˜SNR (>10dB): 95%+ å‡†ç¡®çŽ‡
- ä¸­SNR (0-10dB): 85%+ å‡†ç¡®çŽ‡  
- ä½ŽSNR (<0dB): 70%+ å‡†ç¡®çŽ‡

## ðŸ§ª æ¶ˆèžå®žéªŒ

| ç»„ä»¶ | å‡†ç¡®çŽ‡ | æå‡ |
|------|--------|------|
| åŸºç¡€CNN | 76.2% | - |
| + å¤šå°ºåº¦ | 81.4% | +5.2% |
| + å¤æ•°æ³¨æ„åŠ› | 84.7% | +3.3% |
| + SNRé—¨æŽ§ | 87.3% | +2.6% |

## ðŸ“ˆ ä½¿ç”¨ç¤ºä¾‹

### è‡ªå®šä¹‰è®­ç»ƒ

```python
from src import AMRNet, Trainer, Config
from src.data import DatasetLoader

# åˆ›å»ºé…ç½®
config = Config()
config.training.epochs = 200
config.training.learning_rate = 1e-4

# åŠ è½½æ•°æ®
loader = DatasetLoader(config)
train_loader, val_loader, test_loader = loader.get_dataloaders()

# åˆ›å»ºæ¨¡åž‹
model = AMRNet(num_classes=11)

# è®­ç»ƒ
trainer = Trainer(model, config)
trainer.train(train_loader, val_loader)
```

### æ¨¡åž‹æŽ¨ç†

```python
import torch
from src import AMRNet

# åŠ è½½æ¨¡åž‹
model = AMRNet(num_classes=11)
model.load_state_dict(torch.load('best_model.pth'))
model.eval()

# æŽ¨ç†
with torch.no_grad():
    signal = torch.randn(1, 2, 1024)  # [batch, I/Q, length]
    output = model(signal)
    prediction = torch.argmax(output, dim=1)
```

## ðŸ”§ é…ç½®è¯´æ˜Ž

ä¸»è¦é…ç½®å‚æ•°ï¼š

```yaml
model:
  num_classes: 11
  base_channels: 64
  num_heads: 8
  dropout: 0.1

training:
  epochs: 200
  batch_size: 128
  learning_rate: 1e-4
  scheduler: 'cosine'
  early_stopping: true

data:
  dataset_path: 'dataset/RadioML 2016.10A/RML2016.10a_dict.pkl'
  normalize: true
  augmentation: true
```

## ðŸ“š å¼•ç”¨

å¦‚æžœæ‚¨åœ¨ç ”ç©¶ä¸­ä½¿ç”¨äº†æœ¬é¡¹ç›®ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@article{msac_t_2024,
  title={MSAC-T: A Multi-Scale Analysis with Complex Attention Transformer for Robust Radio Modulation Recognition},
  author={Your Name},
  journal={IEEE Transactions on Signal Processing},
  year={2024}
}
```

## ðŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿Žè´¡çŒ®ä»£ç ï¼è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š

1. Fork æœ¬é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æŽ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯ Pull Request

## ðŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶

## ðŸ“ž è”ç³»æ–¹å¼

- ä½œè€…ï¼š[Your Name]
- é‚®ç®±ï¼šyour.email@example.com
- é¡¹ç›®é“¾æŽ¥ï¼šhttps://github.com/your-username/msac-t-amr

## ðŸ™ è‡´è°¢

- æ„Ÿè°¢ RadioML æ•°æ®é›†çš„æä¾›è€…
- æ„Ÿè°¢å¼€æºç¤¾åŒºçš„è´¡çŒ®
- ç‰¹åˆ«æ„Ÿè°¢ PyTorch å›¢é˜Ÿ

---

â­ å¦‚æžœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä»¬ä¸€ä¸ªæ˜Ÿæ ‡ï¼